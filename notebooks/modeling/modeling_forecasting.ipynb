{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Forecasting Model\n",
        "\n",
        "## Objective\n",
        "Build predictive models for retail sales forecasting using:\n",
        "- Traditional statistical methods (ARIMA)\n",
        "- Machine Learning (Random Forest, XGBoost)\n",
        "- Time series specific models (Prophet)\n",
        "\n",
        "Dataset: https://www.kaggle.com/datasets/mehmettahiraslan/customer-shopping-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import sys\n",
        "from pathlib import Path\n",
        "project_root = Path.cwd().parent.parent\n",
        "sys.path.append(str(project_root / 'scripts'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Try to import XGBoost\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "    print(\"XGBoost not available. Install with: pip install xgboost\")\n",
        "\n",
        "# Try to import Prophet\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    PROPHET_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PROPHET_AVAILABLE = False\n",
        "    print(\"Prophet not available. Install with: pip install prophet\")\n",
        "\n",
        "from utils.db_operations import MongoDBHandler\n",
        "from etl.feature_engineering import FeatureEngineer\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load transformed data with features\n",
        "db_handler = MongoDBHandler()\n",
        "df = db_handler.read_to_dataframe('transformed_sales')\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for modeling\n",
        "# Select features and target\n",
        "feature_cols = [col for col in df.columns if col not in ['invoice_no', 'customer_id', 'invoice_date', 'total_amount']]\n",
        "X = df[feature_cols].select_dtypes(include=[np.number])\n",
        "y = df['total_amount']\n",
        "\n",
        "print(f\"Original data shape: {df.shape}\")\n",
        "print(f\"Features shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values in features: {X.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in target: {y.isnull().sum()}\")\n",
        "\n",
        "# Check which columns have missing values\n",
        "missing_cols = X.columns[X.isnull().any()].tolist()\n",
        "print(f\"\\nColumns with missing values: {missing_cols}\")\n",
        "\n",
        "# Show sample of missing values\n",
        "if missing_cols:\n",
        "    print(f\"\\nSample of missing values in first few columns:\")\n",
        "    for col in missing_cols[:5]:\n",
        "        missing_count = X[col].isnull().sum()\n",
        "        print(f\"{col}: {missing_count} missing values\")\n",
        "\n",
        "# Handle missing values with a more robust strategy\n",
        "print(f\"\\nHandling missing values...\")\n",
        "\n",
        "# For columns that are all NaN, fill with 0\n",
        "# For other columns, fill with median\n",
        "X_filled = X.copy()\n",
        "for col in X_filled.columns:\n",
        "    if X_filled[col].isnull().all():\n",
        "        print(f\"Column '{col}' is all NaN, filling with 0\")\n",
        "        X_filled[col] = 0\n",
        "    else:\n",
        "        median_val = X_filled[col].median()\n",
        "        if pd.isna(median_val):\n",
        "            print(f\"Column '{col}' median is NaN, filling with 0\")\n",
        "            X_filled[col] = X_filled[col].fillna(0)\n",
        "        else:\n",
        "            X_filled[col] = X_filled[col].fillna(median_val)\n",
        "\n",
        "# Handle target variable\n",
        "y_filled = y.fillna(y.median())\n",
        "\n",
        "print(f\"\\nAfter filling missing values:\")\n",
        "print(f\"Features shape: {X_filled.shape}\")\n",
        "print(f\"Target shape: {y_filled.shape}\")\n",
        "print(f\"Missing values in features: {X_filled.isnull().sum().sum()}\")\n",
        "print(f\"Missing values in target: {y_filled.isnull().sum()}\")\n",
        "\n",
        "# Verify no NaN values remain\n",
        "if X_filled.isnull().sum().sum() > 0:\n",
        "    print(f\"\\nWarning: Still have {X_filled.isnull().sum().sum()} missing values!\")\n",
        "    print(\"Columns with remaining NaN values:\")\n",
        "    nan_cols = X_filled.columns[X_filled.isnull().any()].tolist()\n",
        "    for col in nan_cols:\n",
        "        print(f\"  {col}: {X_filled[col].isnull().sum()} missing\")\n",
        "    # Fill any remaining NaN with 0\n",
        "    X_filled = X_filled.fillna(0)\n",
        "    print(\"Filled remaining NaN values with 0\")\n",
        "\n",
        "# Note: Train-test split will be done after data quality check\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Quality Check and Feature Selection\n",
        "print(\"=== DATA QUALITY CHECK ===\")\n",
        "\n",
        "# Check for constant features (zero variance)\n",
        "constant_features = []\n",
        "for col in X_filled.columns:\n",
        "    if X_filled[col].nunique() <= 1:\n",
        "        constant_features.append(col)\n",
        "        print(f\"Constant feature: {col} (unique values: {X_filled[col].nunique()})\")\n",
        "\n",
        "# Remove constant features\n",
        "if constant_features:\n",
        "    print(f\"\\nRemoving {len(constant_features)} constant features...\")\n",
        "    X_filled = X_filled.drop(columns=constant_features)\n",
        "    print(f\"Features after removing constants: {X_filled.shape[1]}\")\n",
        "\n",
        "# Check for highly correlated features\n",
        "print(f\"\\nChecking for highly correlated features...\")\n",
        "correlation_matrix = X_filled.corr().abs()\n",
        "upper_triangle = correlation_matrix.where(\n",
        "    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)\n",
        ")\n",
        "\n",
        "# Find pairs with correlation > 0.95\n",
        "high_corr_pairs = []\n",
        "for i in range(len(upper_triangle.columns)):\n",
        "    for j in range(i):\n",
        "        if upper_triangle.iloc[i, j] > 0.95:\n",
        "            high_corr_pairs.append((upper_triangle.columns[i], upper_triangle.columns[j], upper_triangle.iloc[i, j]))\n",
        "\n",
        "if high_corr_pairs:\n",
        "    print(f\"Found {len(high_corr_pairs)} highly correlated feature pairs (>0.95):\")\n",
        "    for feat1, feat2, corr in high_corr_pairs[:5]:  # Show first 5\n",
        "        print(f\"  {feat1} <-> {feat2}: {corr:.3f}\")\n",
        "\n",
        "# Check data types and ranges\n",
        "print(f\"\\nData Summary:\")\n",
        "print(f\"Features shape: {X_filled.shape}\")\n",
        "print(f\"Data types: {X_filled.dtypes.value_counts().to_dict()}\")\n",
        "print(f\"Value ranges:\")\n",
        "for col in X_filled.columns[:5]:  # Show first 5 columns\n",
        "    print(f\"  {col}: [{X_filled[col].min():.2f}, {X_filled[col].max():.2f}]\")\n",
        "\n",
        "# Final verification\n",
        "print(f\"\\nFinal verification:\")\n",
        "print(f\"Missing values: {X_filled.isnull().sum().sum()}\")\n",
        "print(f\"Infinite values: {np.isinf(X_filled).sum().sum()}\")\n",
        "print(f\"Ready for modeling: {X_filled.isnull().sum().sum() == 0 and np.isinf(X_filled).sum().sum() == 0}\")\n",
        "\n",
        "# Train-test split (after data cleaning)\n",
        "print(f\"\\n=== TRAIN-TEST SPLIT ===\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_filled, y_filled, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "\n",
        "# Verify no missing values in train/test sets\n",
        "print(f\"Training set missing values: {X_train.isnull().sum().sum()}\")\n",
        "print(f\"Test set missing values: {X_test.isnull().sum().sum()}\")\n",
        "print(f\"Training target missing values: {y_train.isnull().sum()}\")\n",
        "print(f\"Test target missing values: {y_test.isnull().sum()}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 1: Linear Regression\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "print(\"Linear Regression Results:\")\n",
        "print(f\"RMSE: {rmse_lr:.2f}\")\n",
        "print(f\"MAE: {mae_lr:.2f}\")\n",
        "print(f\"R² Score: {r2_lr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Investigate the perfect scores issue\n",
        "print(\"=== INVESTIGATING PERFECT SCORES ===\")\n",
        "\n",
        "# Check if there's data leakage\n",
        "print(\"1. Checking for data leakage...\")\n",
        "print(f\"Target variable name: 'total_amount'\")\n",
        "print(f\"Features containing 'total_amount': {[col for col in X_train.columns if 'total_amount' in col.lower()]}\")\n",
        "\n",
        "# Check if target is perfectly predictable\n",
        "print(f\"\\n2. Target variable statistics:\")\n",
        "print(f\"Target mean: {y_train.mean():.4f}\")\n",
        "print(f\"Target std: {y_train.std():.4f}\")\n",
        "print(f\"Target min: {y_train.min():.4f}\")\n",
        "print(f\"Target max: {y_train.max():.4f}\")\n",
        "\n",
        "# Check for constant target\n",
        "print(f\"Target unique values: {y_train.nunique()}\")\n",
        "print(f\"Target is constant: {y_train.nunique() == 1}\")\n",
        "\n",
        "# Check feature-target correlation\n",
        "print(f\"\\n3. Feature-target correlations (top 10):\")\n",
        "correlations = []\n",
        "for col in X_train.columns:\n",
        "    corr = X_train[col].corr(y_train)\n",
        "    if not pd.isna(corr):\n",
        "        correlations.append((col, corr))\n",
        "\n",
        "correlations.sort(key=lambda x: abs(x[1]), reverse=True)\n",
        "for col, corr in correlations[:10]:\n",
        "    print(f\"  {col}: {corr:.4f}\")\n",
        "\n",
        "# Check if any feature is identical to target\n",
        "print(f\"\\n4. Checking for identical features to target:\")\n",
        "for col in X_train.columns:\n",
        "    if X_train[col].equals(y_train):\n",
        "        print(f\"  WARNING: Feature '{col}' is identical to target!\")\n",
        "    elif X_train[col].corr(y_train) > 0.999:\n",
        "        print(f\"  WARNING: Feature '{col}' is almost identical to target (corr: {X_train[col].corr(y_train):.4f})\")\n",
        "\n",
        "# Check predictions vs actual\n",
        "print(f\"\\n5. Prediction analysis:\")\n",
        "print(f\"Predictions range: [{y_pred_lr.min():.4f}, {y_pred_lr.max():.4f}]\")\n",
        "print(f\"Actual range: [{y_test.min():.4f}, {y_test.max():.4f}]\")\n",
        "print(f\"Predictions == Actual: {np.allclose(y_pred_lr, y_test)}\")\n",
        "\n",
        "# Note: Random Forest model not yet trained, skipping feature importance for now\n",
        "print(f\"\\n6. Data Leakage Summary:\")\n",
        "print(f\"Found {len([col for col in X_train.columns if X_train[col].corr(y_train) > 0.999])} features with perfect correlation to target\")\n",
        "print(f\"These features are essentially identical to the target variable, causing perfect predictions\")\n",
        "print(f\"This is why we get RMSE=0.00, MAE=0.00, and R²=1.0000\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fix data leakage by removing problematic features\n",
        "print(\"=== FIXING DATA LEAKAGE ===\")\n",
        "\n",
        "# Remove features that are highly correlated with target (potential data leakage)\n",
        "high_corr_features = []\n",
        "for col in X_train.columns:\n",
        "    corr = abs(X_train[col].corr(y_train))\n",
        "    if corr > 0.95:  # Very high correlation threshold\n",
        "        high_corr_features.append(col)\n",
        "        print(f\"Removing high correlation feature: {col} (corr: {corr:.4f})\")\n",
        "\n",
        "# Remove features that might contain target information\n",
        "target_related_features = [col for col in X_train.columns if 'total_amount' in col.lower()]\n",
        "print(f\"\\nRemoving target-related features: {target_related_features}\")\n",
        "\n",
        "# Combine all problematic features\n",
        "problematic_features = list(set(high_corr_features + target_related_features))\n",
        "print(f\"\\nTotal problematic features to remove: {len(problematic_features)}\")\n",
        "\n",
        "# Create clean feature set\n",
        "X_clean = X_train.drop(columns=problematic_features)\n",
        "X_test_clean = X_test.drop(columns=problematic_features)\n",
        "\n",
        "print(f\"\\nOriginal features: {X_train.shape[1]}\")\n",
        "print(f\"Clean features: {X_clean.shape[1]}\")\n",
        "print(f\"Removed features: {X_train.shape[1] - X_clean.shape[1]}\")\n",
        "\n",
        "# Verify no data leakage in clean data\n",
        "print(f\"\\nVerifying clean data:\")\n",
        "clean_correlations = []\n",
        "for col in X_clean.columns:\n",
        "    corr = abs(X_clean[col].corr(y_train))\n",
        "    if corr > 0.9:\n",
        "        clean_correlations.append((col, corr))\n",
        "\n",
        "if clean_correlations:\n",
        "    print(f\"WARNING: Still have {len(clean_correlations)} highly correlated features:\")\n",
        "    for col, corr in clean_correlations:\n",
        "        print(f\"  {col}: {corr:.4f}\")\n",
        "else:\n",
        "    print(\"✓ No highly correlated features remaining\")\n",
        "\n",
        "# Retrain models with clean data\n",
        "print(\"\\n=== RETRAINING MODELS WITH CLEAN DATA ===\")\n",
        "\n",
        "# Linear Regression\n",
        "lr_clean = LinearRegression()\n",
        "lr_clean.fit(X_clean, y_train)\n",
        "y_pred_lr_clean = lr_clean.predict(X_test_clean)\n",
        "\n",
        "# Evaluate clean Linear Regression\n",
        "mse_lr_clean = mean_squared_error(y_test, y_pred_lr_clean)\n",
        "rmse_lr_clean = np.sqrt(mse_lr_clean)\n",
        "mae_lr_clean = mean_absolute_error(y_test, y_pred_lr_clean)\n",
        "r2_lr_clean = r2_score(y_test, y_pred_lr_clean)\n",
        "\n",
        "print(\"Clean Linear Regression Results:\")\n",
        "print(f\"RMSE: {rmse_lr_clean:.2f}\")\n",
        "print(f\"MAE: {mae_lr_clean:.2f}\")\n",
        "print(f\"R² Score: {r2_lr_clean:.4f}\")\n",
        "\n",
        "# Random Forest\n",
        "rf_clean = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_clean.fit(X_clean, y_train)\n",
        "y_pred_rf_clean = rf_clean.predict(X_test_clean)\n",
        "\n",
        "# Evaluate clean Random Forest\n",
        "mse_rf_clean = mean_squared_error(y_test, y_pred_rf_clean)\n",
        "rmse_rf_clean = np.sqrt(mse_rf_clean)\n",
        "mae_rf_clean = mean_absolute_error(y_test, y_pred_rf_clean)\n",
        "r2_rf_clean = r2_score(y_test, y_pred_rf_clean)\n",
        "\n",
        "print(\"\\nClean Random Forest Results:\")\n",
        "print(f\"RMSE: {rmse_rf_clean:.2f}\")\n",
        "print(f\"MAE: {mae_rf_clean:.2f}\")\n",
        "print(f\"R² Score: {r2_rf_clean:.4f}\")\n",
        "\n",
        "# Feature importance for clean Random Forest\n",
        "print(\"\\nClean Random Forest Feature Importance:\")\n",
        "feature_importance_clean = pd.DataFrame({\n",
        "    'feature': X_clean.columns,\n",
        "    'importance': rf_clean.feature_importances_\n",
        "}).sort_values('importance', ascending=False).head(10)\n",
        "\n",
        "print(feature_importance_clean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 2: Random Forest\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "rmse_rf = np.sqrt(mse_rf)\n",
        "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
        "r2_rf = r2_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Random Forest Results:\")\n",
        "print(f\"RMSE: {rmse_rf:.2f}\")\n",
        "print(f\"MAE: {mae_rf:.2f}\")\n",
        "print(f\"R² Score: {r2_rf:.4f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_filled.columns,\n",
        "    'importance': rf_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False).head(10)\n",
        "\n",
        "print(\"\\nTop 10 Important Features:\")\n",
        "print(feature_importance)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model comparison visualization (using clean results)\n",
        "print(\"=== MODEL COMPARISON (CLEAN DATA) ===\")\n",
        "\n",
        "models_data = {\n",
        "    'Model': ['Linear Regression (Clean)', 'Random Forest (Clean)'],\n",
        "    'RMSE': [rmse_lr_clean, rmse_rf_clean],\n",
        "    'MAE': [mae_lr_clean, mae_rf_clean],\n",
        "    'R² Score': [r2_lr_clean, r2_rf_clean]\n",
        "}\n",
        "\n",
        "# Add XGBoost if available\n",
        "if XGBOOST_AVAILABLE and rmse_xgb is not None:\n",
        "    models_data['Model'].append('XGBoost')\n",
        "    models_data['RMSE'].append(rmse_xgb)\n",
        "    models_data['MAE'].append(mae_xgb)\n",
        "    models_data['R² Score'].append(r2_xgb)\n",
        "\n",
        "results = pd.DataFrame(models_data)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "results.plot(x='Model', y='RMSE', kind='bar', ax=axes[0], legend=False)\n",
        "axes[0].set_title('RMSE Comparison (Lower is Better)')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "results.plot(x='Model', y='MAE', kind='bar', ax=axes[1], legend=False, color='orange')\n",
        "axes[1].set_title('MAE Comparison (Lower is Better)')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "results.plot(x='Model', y='R² Score', kind='bar', ax=axes[2], legend=False, color='green')\n",
        "axes[2].set_title('R² Score Comparison (Higher is Better)')\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClean Model Comparison Summary:\")\n",
        "print(results.round(4))\n",
        "\n",
        "# Compare with original (problematic) results\n",
        "print(\"\\n=== COMPARISON: ORIGINAL vs CLEAN ===\")\n",
        "comparison_data = {\n",
        "    'Model': ['Linear Regression (Original)', 'Linear Regression (Clean)', \n",
        "              'Random Forest (Original)', 'Random Forest (Clean)'],\n",
        "    'RMSE': [rmse_lr, rmse_lr_clean, rmse_rf, rmse_rf_clean],\n",
        "    'MAE': [mae_lr, mae_lr_clean, mae_rf, mae_rf_clean],\n",
        "    'R² Score': [r2_lr, r2_lr_clean, r2_rf, r2_rf_clean]\n",
        "}\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df.round(4))\n",
        "\n",
        "print(\"\\n=== ANALYSIS ===\")\n",
        "print(\"The original models showed perfect scores due to data leakage.\")\n",
        "print(\"Features containing 'total_amount' or highly correlated with target were removed.\")\n",
        "print(\"Clean models show more realistic performance metrics.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model 3: XGBoost (if available)\n",
        "if XGBOOST_AVAILABLE:\n",
        "    xgb_model = xgb.XGBRegressor(\n",
        "        n_estimators=100,\n",
        "        max_depth=6,\n",
        "        learning_rate=0.1,\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    xgb_model.fit(X_train, y_train)\n",
        "    y_pred_xgb = xgb_model.predict(X_test)\n",
        "    \n",
        "    # Evaluate\n",
        "    mse_xgb = mean_squared_error(y_test, y_pred_xgb)\n",
        "    rmse_xgb = np.sqrt(mse_xgb)\n",
        "    mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
        "    r2_xgb = r2_score(y_test, y_pred_xgb)\n",
        "    \n",
        "    print(\"XGBoost Results:\")\n",
        "    print(f\"RMSE: {rmse_xgb:.2f}\")\n",
        "    print(f\"MAE: {mae_xgb:.2f}\")\n",
        "    print(f\"R² Score: {r2_xgb:.4f}\")\n",
        "    \n",
        "    # Feature importance for XGBoost\n",
        "    xgb_importance = pd.DataFrame({\n",
        "        'feature': X_filled.columns,\n",
        "        'importance': xgb_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False).head(10)\n",
        "    \n",
        "    print(\"\\nTop 10 Important Features (XGBoost):\")\n",
        "    print(xgb_importance)\n",
        "else:\n",
        "    print(\"XGBoost not available. Skipping XGBoost model.\")\n",
        "    rmse_xgb = mae_xgb = r2_xgb = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fixed Prophet Time Series Forecasting with Error Handling\n",
        "print(\"\\n=== PROPHET TIME SERIES FORECASTING (FIXED) ===\")\n",
        "\n",
        "if PROPHET_AVAILABLE:\n",
        "    try:\n",
        "        # Prepare data for Prophet\n",
        "        prophet_data = daily_sales.copy()\n",
        "        prophet_data.columns = ['ds', 'y']  # Prophet expects 'ds' for dates and 'y' for values\n",
        "        \n",
        "        # Split data for training and testing\n",
        "        train_size = int(len(prophet_data) * 0.8)\n",
        "        train_data = prophet_data[:train_size]\n",
        "        test_data = prophet_data[train_size:]\n",
        "        \n",
        "        print(f\"Training data: {len(train_data)} days\")\n",
        "        print(f\"Test data: {len(test_data)} days\")\n",
        "        \n",
        "        # Try Prophet with different configurations\n",
        "        try:\n",
        "            # First try with minimal configuration\n",
        "            model = Prophet(\n",
        "                yearly_seasonality=True,\n",
        "                weekly_seasonality=True,\n",
        "                daily_seasonality=False\n",
        "            )\n",
        "            model.fit(train_data)\n",
        "            \n",
        "            # Make predictions\n",
        "            future = model.make_future_dataframe(periods=len(test_data))\n",
        "            forecast = model.predict(future)\n",
        "            \n",
        "            # Evaluate on test set\n",
        "            predictions = forecast['yhat'][train_size:].values\n",
        "            actual = test_data['y'].values\n",
        "            \n",
        "            mse_prophet = mean_squared_error(actual, predictions)\n",
        "            rmse_prophet = np.sqrt(mse_prophet)\n",
        "            mae_prophet = mean_absolute_error(actual, predictions)\n",
        "            r2_prophet = r2_score(actual, predictions)\n",
        "            \n",
        "            print(f\"\\nProphet Results:\")\n",
        "            print(f\"RMSE: {rmse_prophet:.2f}\")\n",
        "            print(f\"MAE: {mae_prophet:.2f}\")\n",
        "            print(f\"R² Score: {r2_prophet:.4f}\")\n",
        "            \n",
        "            # Plot Prophet forecast\n",
        "            fig = model.plot(forecast)\n",
        "            plt.title('Prophet Time Series Forecast')\n",
        "            plt.show()\n",
        "            \n",
        "            # Plot components\n",
        "            fig = model.plot_components(forecast)\n",
        "            plt.show()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Prophet failed: {str(e)}\")\n",
        "            print(\"Using alternative time series approach...\")\n",
        "            \n",
        "            # Alternative: Simple time series forecasting using sklearn\n",
        "            from sklearn.linear_model import LinearRegression\n",
        "            from sklearn.preprocessing import PolynomialFeatures\n",
        "            \n",
        "            # Create time-based features\n",
        "            train_data_alt = train_data.copy()\n",
        "            train_data_alt['day_of_year'] = pd.to_datetime(train_data_alt['ds']).dt.dayofyear\n",
        "            train_data_alt['month'] = pd.to_datetime(train_data_alt['ds']).dt.month\n",
        "            train_data_alt['day_of_week'] = pd.to_datetime(train_data_alt['ds']).dt.dayofweek\n",
        "            train_data_alt['quarter'] = pd.to_datetime(train_data_alt['ds']).dt.quarter\n",
        "            \n",
        "            test_data_alt = test_data.copy()\n",
        "            test_data_alt['day_of_year'] = pd.to_datetime(test_data_alt['ds']).dt.dayofyear\n",
        "            test_data_alt['month'] = pd.to_datetime(test_data_alt['ds']).dt.month\n",
        "            test_data_alt['day_of_week'] = pd.to_datetime(test_data_alt['ds']).dt.dayofweek\n",
        "            test_data_alt['quarter'] = pd.to_datetime(test_data_alt['ds']).dt.quarter\n",
        "            \n",
        "            # Prepare features\n",
        "            X_train_ts = train_data_alt[['day_of_year', 'month', 'day_of_week', 'quarter']].values\n",
        "            y_train_ts = train_data_alt['y'].values\n",
        "            X_test_ts = test_data_alt[['day_of_year', 'month', 'day_of_week', 'quarter']].values\n",
        "            y_test_ts = test_data_alt['y'].values\n",
        "            \n",
        "            # Fit polynomial regression for time series\n",
        "            poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "            X_train_poly = poly.fit_transform(X_train_ts)\n",
        "            X_test_poly = poly.transform(X_test_ts)\n",
        "            \n",
        "            ts_model = LinearRegression()\n",
        "            ts_model.fit(X_train_poly, y_train_ts)\n",
        "            predictions = ts_model.predict(X_test_poly)\n",
        "            \n",
        "            # Evaluate\n",
        "            mse_prophet = mean_squared_error(y_test_ts, predictions)\n",
        "            rmse_prophet = np.sqrt(mse_prophet)\n",
        "            mae_prophet = mean_absolute_error(y_test_ts, predictions)\n",
        "            r2_prophet = r2_score(y_test_ts, predictions)\n",
        "            \n",
        "            print(f\"\\nAlternative Time Series Results (Polynomial Regression):\")\n",
        "            print(f\"RMSE: {rmse_prophet:.2f}\")\n",
        "            print(f\"MAE: {mae_prophet:.2f}\")\n",
        "            print(f\"R² Score: {r2_prophet:.4f}\")\n",
        "            \n",
        "            # Plot results\n",
        "            plt.figure(figsize=(15, 6))\n",
        "            plt.plot(range(len(y_test_ts)), y_test_ts, label='Actual', alpha=0.7, linewidth=2)\n",
        "            plt.plot(range(len(predictions)), predictions, label='Predicted', alpha=0.7, linewidth=2)\n",
        "            plt.title('Time Series Forecasting (Alternative Method)')\n",
        "            plt.xlabel('Time')\n",
        "            plt.ylabel('Sales Amount')\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.show()\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Time series analysis failed: {str(e)}\")\n",
        "        rmse_prophet = mae_prophet = r2_prophet = None\n",
        "        \n",
        "else:\n",
        "    print(\"Prophet not available. Using alternative time series approach...\")\n",
        "    \n",
        "    # Alternative time series analysis\n",
        "    try:\n",
        "        # Create time-based features for daily sales\n",
        "        daily_sales_alt = daily_sales.copy()\n",
        "        daily_sales_alt['day_of_year'] = pd.to_datetime(daily_sales_alt['invoice_date']).dt.dayofyear\n",
        "        daily_sales_alt['month'] = pd.to_datetime(daily_sales_alt['invoice_date']).dt.month\n",
        "        daily_sales_alt['day_of_week'] = pd.to_datetime(daily_sales_alt['invoice_date']).dt.dayofweek\n",
        "        daily_sales_alt['quarter'] = pd.to_datetime(daily_sales_alt['invoice_date']).dt.quarter\n",
        "        \n",
        "        # Split data\n",
        "        train_size = int(len(daily_sales_alt) * 0.8)\n",
        "        train_data = daily_sales_alt[:train_size]\n",
        "        test_data = daily_sales_alt[train_size:]\n",
        "        \n",
        "        # Prepare features\n",
        "        X_train_ts = train_data[['day_of_year', 'month', 'day_of_week', 'quarter']].values\n",
        "        y_train_ts = train_data['total_amount'].values\n",
        "        X_test_ts = test_data[['day_of_year', 'month', 'day_of_week', 'quarter']].values\n",
        "        y_test_ts = test_data['total_amount'].values\n",
        "        \n",
        "        # Fit polynomial regression\n",
        "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "        X_train_poly = poly.fit_transform(X_train_ts)\n",
        "        X_test_poly = poly.transform(X_test_ts)\n",
        "        \n",
        "        ts_model = LinearRegression()\n",
        "        ts_model.fit(X_train_poly, y_train_ts)\n",
        "        predictions = ts_model.predict(X_test_poly)\n",
        "        \n",
        "        # Evaluate\n",
        "        mse_prophet = mean_squared_error(y_test_ts, predictions)\n",
        "        rmse_prophet = np.sqrt(mse_prophet)\n",
        "        mae_prophet = mean_absolute_error(y_test_ts, predictions)\n",
        "        r2_prophet = r2_score(y_test_ts, predictions)\n",
        "        \n",
        "        print(f\"\\nAlternative Time Series Results:\")\n",
        "        print(f\"RMSE: {rmse_prophet:.2f}\")\n",
        "        print(f\"MAE: {mae_prophet:.2f}\")\n",
        "        print(f\"R² Score: {r2_prophet:.4f}\")\n",
        "        \n",
        "        # Plot results\n",
        "        plt.figure(figsize=(15, 6))\n",
        "        plt.plot(range(len(y_test_ts)), y_test_ts, label='Actual', alpha=0.7, linewidth=2)\n",
        "        plt.plot(range(len(predictions)), predictions, label='Predicted', alpha=0.7, linewidth=2)\n",
        "        plt.title('Time Series Forecasting (Alternative Method)')\n",
        "        plt.xlabel('Time')\n",
        "        plt.ylabel('Sales Amount')\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.show()\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Alternative time series failed: {str(e)}\")\n",
        "        rmse_prophet = mae_prophet = r2_prophet = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick Fix: Skip Prophet and use alternative time series approach\n",
        "print(\"=== TIME SERIES FORECASTING (ALTERNATIVE METHOD) ===\")\n",
        "\n",
        "# Create time series data\n",
        "df_ts = df.copy()\n",
        "df_ts['invoice_date'] = pd.to_datetime(df_ts['invoice_date'])\n",
        "\n",
        "# Create daily sales aggregation\n",
        "daily_sales = df_ts.groupby('invoice_date')['total_amount'].sum().reset_index()\n",
        "daily_sales = daily_sales.sort_values('invoice_date')\n",
        "\n",
        "print(f\"Time series data shape: {daily_sales.shape}\")\n",
        "print(f\"Date range: {daily_sales['invoice_date'].min()} to {daily_sales['invoice_date'].max()}\")\n",
        "\n",
        "# Create time-based features\n",
        "daily_sales['day_of_year'] = daily_sales['invoice_date'].dt.dayofyear\n",
        "daily_sales['month'] = daily_sales['invoice_date'].dt.month\n",
        "daily_sales['day_of_week'] = daily_sales['invoice_date'].dt.dayofweek\n",
        "daily_sales['quarter'] = daily_sales['invoice_date'].dt.quarter\n",
        "daily_sales['year'] = daily_sales['invoice_date'].dt.year\n",
        "\n",
        "# Split data for training and testing\n",
        "train_size = int(len(daily_sales) * 0.8)\n",
        "train_data = daily_sales[:train_size]\n",
        "test_data = daily_sales[train_size:]\n",
        "\n",
        "print(f\"Training data: {len(train_data)} days\")\n",
        "print(f\"Test data: {len(test_data)} days\")\n",
        "\n",
        "# Prepare features\n",
        "X_train_ts = train_data[['day_of_year', 'month', 'day_of_week', 'quarter', 'year']].values\n",
        "y_train_ts = train_data['total_amount'].values\n",
        "X_test_ts = test_data[['day_of_year', 'month', 'day_of_week', 'quarter', 'year']].values\n",
        "y_test_ts = test_data['total_amount'].values\n",
        "\n",
        "# Fit polynomial regression for time series\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train_ts)\n",
        "X_test_poly = poly.transform(X_test_ts)\n",
        "\n",
        "ts_model = LinearRegression()\n",
        "ts_model.fit(X_train_poly, y_train_ts)\n",
        "predictions = ts_model.predict(X_test_poly)\n",
        "\n",
        "# Evaluate\n",
        "mse_prophet = mean_squared_error(y_test_ts, predictions)\n",
        "rmse_prophet = np.sqrt(mse_prophet)\n",
        "mae_prophet = mean_absolute_error(y_test_ts, predictions)\n",
        "r2_prophet = r2_score(y_test_ts, predictions)\n",
        "\n",
        "print(f\"\\nTime Series Forecasting Results:\")\n",
        "print(f\"RMSE: {rmse_prophet:.2f}\")\n",
        "print(f\"MAE: {mae_prophet:.2f}\")\n",
        "print(f\"R² Score: {r2_prophet:.4f}\")\n",
        "\n",
        "# Plot results\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "# Plot 1: Time series forecast\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(range(len(y_test_ts)), y_test_ts, label='Actual', alpha=0.7, linewidth=2, color='blue')\n",
        "plt.plot(range(len(predictions)), predictions, label='Predicted', alpha=0.7, linewidth=2, color='red')\n",
        "plt.title('Time Series Forecasting: Actual vs Predicted')\n",
        "plt.xlabel('Time (Days)')\n",
        "plt.ylabel('Sales Amount')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Scatter plot\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.scatter(y_test_ts, predictions, alpha=0.6, color='green')\n",
        "plt.plot([y_test_ts.min(), y_test_ts.max()], [y_test_ts.min(), y_test_ts.max()], 'r--', lw=2)\n",
        "plt.xlabel('Actual Sales')\n",
        "plt.ylabel('Predicted Sales')\n",
        "plt.title('Prediction Accuracy Scatter Plot')\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Feature importance for time series\n",
        "feature_names = ['day_of_year', 'month', 'day_of_week', 'quarter', 'year']\n",
        "feature_importance_ts = pd.DataFrame({\n",
        "    'feature': feature_names,\n",
        "    'coefficient': ts_model.coef_[:len(feature_names)]\n",
        "}).sort_values('coefficient', key=abs, ascending=False)\n",
        "\n",
        "print(\"\\nTime Series Feature Importance:\")\n",
        "print(feature_importance_ts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model comparison visualization\n",
        "models_data = {\n",
        "    'Model': ['Linear Regression', 'Random Forest'],\n",
        "    'RMSE': [rmse_lr, rmse_rf],\n",
        "    'MAE': [mae_lr, mae_rf],\n",
        "    'R² Score': [r2_lr, r2_rf]\n",
        "}\n",
        "\n",
        "# Add XGBoost if available\n",
        "if XGBOOST_AVAILABLE and rmse_xgb is not None:\n",
        "    models_data['Model'].append('XGBoost')\n",
        "    models_data['RMSE'].append(rmse_xgb)\n",
        "    models_data['MAE'].append(mae_xgb)\n",
        "    models_data['R² Score'].append(r2_xgb)\n",
        "\n",
        "results = pd.DataFrame(models_data)\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "results.plot(x='Model', y='RMSE', kind='bar', ax=axes[0], legend=False)\n",
        "axes[0].set_title('RMSE Comparison')\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "results.plot(x='Model', y='MAE', kind='bar', ax=axes[1], legend=False, color='orange')\n",
        "axes[1].set_title('MAE Comparison')\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "results.plot(x='Model', y='R² Score', kind='bar', ax=axes[2], legend=False, color='green')\n",
        "axes[2].set_title('R² Score Comparison')\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nModel Comparison Summary:\")\n",
        "print(results.round(4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Time Series Analysis\n",
        "print(\"=== TIME SERIES ANALYSIS ===\")\n",
        "\n",
        "# Convert invoice_date to datetime and create time series\n",
        "df_ts = df.copy()\n",
        "df_ts['invoice_date'] = pd.to_datetime(df_ts['invoice_date'])\n",
        "\n",
        "# Create daily sales aggregation\n",
        "daily_sales = df_ts.groupby('invoice_date')['total_amount'].sum().reset_index()\n",
        "daily_sales = daily_sales.sort_values('invoice_date')\n",
        "\n",
        "print(f\"Time series data shape: {daily_sales.shape}\")\n",
        "print(f\"Date range: {daily_sales['invoice_date'].min()} to {daily_sales['invoice_date'].max()}\")\n",
        "\n",
        "# Plot time series\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.plot(daily_sales['invoice_date'], daily_sales['total_amount'])\n",
        "plt.title('Daily Sales Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Total Sales Amount')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Basic time series statistics\n",
        "print(f\"\\nTime Series Statistics:\")\n",
        "print(f\"Mean daily sales: {daily_sales['total_amount'].mean():.2f}\")\n",
        "print(f\"Std daily sales: {daily_sales['total_amount'].std():.2f}\")\n",
        "print(f\"Min daily sales: {daily_sales['total_amount'].min():.2f}\")\n",
        "print(f\"Max daily sales: {daily_sales['total_amount'].max():.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prophet Time Series Forecasting (if available)\n",
        "if PROPHET_AVAILABLE:\n",
        "    print(\"\\n=== PROPHET TIME SERIES FORECASTING ===\")\n",
        "    \n",
        "    # Prepare data for Prophet\n",
        "    prophet_data = daily_sales.copy()\n",
        "    prophet_data.columns = ['ds', 'y']  # Prophet expects 'ds' for dates and 'y' for values\n",
        "    \n",
        "    # Split data for training and testing\n",
        "    train_size = int(len(prophet_data) * 0.8)\n",
        "    train_data = prophet_data[:train_size]\n",
        "    test_data = prophet_data[train_size:]\n",
        "    \n",
        "    print(f\"Training data: {len(train_data)} days\")\n",
        "    print(f\"Test data: {len(test_data)} days\")\n",
        "    \n",
        "    # Create and fit Prophet model\n",
        "    model = Prophet(\n",
        "        yearly_seasonality=True,\n",
        "        weekly_seasonality=True,\n",
        "        daily_seasonality=False,\n",
        "        seasonality_mode='multiplicative'\n",
        "    )\n",
        "    \n",
        "    model.fit(train_data)\n",
        "    \n",
        "    # Make predictions\n",
        "    future = model.make_future_dataframe(periods=len(test_data))\n",
        "    forecast = model.predict(future)\n",
        "    \n",
        "    # Evaluate on test set\n",
        "    predictions = forecast['yhat'][train_size:].values\n",
        "    actual = test_data['y'].values\n",
        "    \n",
        "    mse_prophet = mean_squared_error(actual, predictions)\n",
        "    rmse_prophet = np.sqrt(mse_prophet)\n",
        "    mae_prophet = mean_absolute_error(actual, predictions)\n",
        "    r2_prophet = r2_score(actual, predictions)\n",
        "    \n",
        "    print(f\"\\nProphet Results:\")\n",
        "    print(f\"RMSE: {rmse_prophet:.2f}\")\n",
        "    print(f\"MAE: {mae_prophet:.2f}\")\n",
        "    print(f\"R² Score: {r2_prophet:.4f}\")\n",
        "    \n",
        "    # Plot Prophet forecast\n",
        "    fig = model.plot(forecast)\n",
        "    plt.title('Prophet Time Series Forecast')\n",
        "    plt.show()\n",
        "    \n",
        "    # Plot components\n",
        "    fig = model.plot_components(forecast)\n",
        "    plt.show()\n",
        "    \n",
        "else:\n",
        "    print(\"\\nProphet not available. Skipping time series forecasting.\")\n",
        "    rmse_prophet = mae_prophet = r2_prophet = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Model Comparison\n",
        "print(\"\\n=== FINAL MODEL COMPARISON ===\")\n",
        "\n",
        "# Create comprehensive comparison\n",
        "all_models_data = {\n",
        "    'Model': ['Linear Regression', 'Random Forest'],\n",
        "    'RMSE': [rmse_lr, rmse_rf],\n",
        "    'MAE': [mae_lr, mae_rf],\n",
        "    'R² Score': [r2_lr, r2_rf],\n",
        "    'Type': ['ML', 'ML']\n",
        "}\n",
        "\n",
        "# Add XGBoost if available\n",
        "if XGBOOST_AVAILABLE and rmse_xgb is not None:\n",
        "    all_models_data['Model'].append('XGBoost')\n",
        "    all_models_data['RMSE'].append(rmse_xgb)\n",
        "    all_models_data['MAE'].append(mae_xgb)\n",
        "    all_models_data['R² Score'].append(r2_xgb)\n",
        "    all_models_data['Type'].append('ML')\n",
        "\n",
        "# Add Prophet if available\n",
        "if PROPHET_AVAILABLE and rmse_prophet is not None:\n",
        "    all_models_data['Model'].append('Prophet')\n",
        "    all_models_data['RMSE'].append(rmse_prophet)\n",
        "    all_models_data['MAE'].append(mae_prophet)\n",
        "    all_models_data['R² Score'].append(r2_prophet)\n",
        "    all_models_data['Type'].append('Time Series')\n",
        "\n",
        "final_results = pd.DataFrame(all_models_data)\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "# RMSE comparison\n",
        "final_results.plot(x='Model', y='RMSE', kind='bar', ax=axes[0,0], legend=False, color='skyblue')\n",
        "axes[0,0].set_title('RMSE Comparison (Lower is Better)')\n",
        "axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# MAE comparison\n",
        "final_results.plot(x='Model', y='MAE', kind='bar', ax=axes[0,1], legend=False, color='lightcoral')\n",
        "axes[0,1].set_title('MAE Comparison (Lower is Better)')\n",
        "axes[0,1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# R² Score comparison\n",
        "final_results.plot(x='Model', y='R² Score', kind='bar', ax=axes[1,0], legend=False, color='lightgreen')\n",
        "axes[1,0].set_title('R² Score Comparison (Higher is Better)')\n",
        "axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# Model type distribution\n",
        "type_counts = final_results['Type'].value_counts()\n",
        "axes[1,1].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', startangle=90)\n",
        "axes[1,1].set_title('Model Type Distribution')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nFinal Model Comparison Summary:\")\n",
        "print(final_results.round(4))\n",
        "\n",
        "# Find best model\n",
        "best_rmse_idx = final_results['RMSE'].idxmin()\n",
        "best_r2_idx = final_results['R² Score'].idxmax()\n",
        "\n",
        "print(f\"\\nBest Model by RMSE: {final_results.loc[best_rmse_idx, 'Model']} (RMSE: {final_results.loc[best_rmse_idx, 'RMSE']:.4f})\")\n",
        "print(f\"Best Model by R² Score: {final_results.loc[best_r2_idx, 'Model']} (R²: {final_results.loc[best_r2_idx, 'R² Score']:.4f})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
